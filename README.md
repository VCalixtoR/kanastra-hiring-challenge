# FAST-API

<h3 align="center">
  API de processamento de boletos
</h3>


<p align="center">
  <a href="#-sobre-o-projeto">Sobre o projeto</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
  <a href="#-resultados">Funcionamento</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
  <a href="#-cen√°rio-real">Cen√°rio real</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
  <a href="#-build-na-cloud-para-dev-e-prod">Build na Cloud para DEV e PROD</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
  <a href="#-execu√ß√£o-local">Execu√ß√£o local</a>&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
  <a href="#-como-contribuir">Como contribuir</a>&nbsp;&nbsp;&nbsp;
</p>

## üíáüèª‚Äç‚ôÇÔ∏è Sobre o projeto

Este repositorio possui uma solu√ß√£o para uma entrevista da Kanastra incompleta mas que possui uma solu√ß√£o bem arquitetada, meu objetivo √©, al√©m de usar para a entrevista, utilizar esta arquitetura para criar um boilerplate com as boas pr√°ticas que fui conhecendo ao longo da minha carreira para a comunidade.

A tarefa √© dedicada ao processamento de um arquivo csv que quando enviado via request, √© processado pela API (Uso de FastAPI) para a gera√ß√£o de boletos com base em seus dados seguido pelo envio por email do resultado a cada usu√°rios

## üí° Resultados

Conforme citado anteriormente, a solu√ß√£o que entreguei a tempo foi mais focada na arquitetura ao inv√©s da funcionalidade da API, infelizmente eu n√£o tive o tempo para finalizar a solu√ß√£o, mas listo aqui, resumidamente, os pontos importantes que trouxe para mostrar minhas qualidades:

- **M√≥dulos da arquitetura que favorece o principio de responsabilidade unica**: A arquitetura em m√≥dulos foi pensada para separar bem cada componente da arquitetura.
- **ORM com SQLAlchemy para abstra√ß√£o da base de dados**: O uso do ORM que permite o mapeamento de estruturas em python para modelos das bases de dados permite opera√ß√µes CRUD facilitadas na API al√©m de facilitar a migra√ß√£o de diferentes bases de dados quando necess√°rio. Nesta solu√ß√£o por exemplo, localmente √© poss√≠vel usar sqlite j√° em dev ou prod pode ser usado Postgres, MySQL do Cloud SQL da GCP ou RDS da AWS, para isso, basta apenas mudar a URL de conex√£o e todas as tabelas e sintaxe s√£o mapeadas para o modelo da nova base pelo SQLAlchemy.
- **Providers criados com invers√£o de dependencia e injetados nos trechos necess√°rios**: Favorece o desacoplamento e reuso facilitado dos providers, al√©m de evitar side efects de mudan√ßas internas das classes que implementam as interfaces, verifique /providers/app_injector.py para ver o container de inje√ß√£o que √© reutilizado para isto.
- **Logs s√£o bem estruturados e com a invers√£o de dependencia**: Poss√≠vel modifica-los sem precisar alterar o c√≥digo que os chamam (Exemplo: Se for necess√°rio colocar logs do grafana, basta alterar a linha `self.operation_logger = self.custom_uvicorn_logger.get_logger(IServicesEnum.PROCESS_FILE, self.operation_logger_id)` para retornar um operation_logger que √© uma inst√¢ncia de uma classe que implementa a interface da invers√£o e que tenha os metodos .info, .warn, etc que enviam os dados para o Grafana ou outra ferramenta de monitoramento).
- **Docker e Docker-compose**: √â montado um container docker simples mas bem pensado para evitar recarregamentos das layers do docker-compose ap√≥s atualiza√ß√µes (Verifique o Dockerfile). O Dockercompose √© mais pensado para a execu√ß√£o facilitada localmente.
- **Subida pra cloud**: Esta vers√£o possui integra√ß√£o com a minha cloud para versionar a API em um Cloud Run da GCP usando CI CD (Verifique o cloudbuild.yaml), isso permite escalabilidade horizontal, o que apenas o uso de threads alvo desta tarefa n√£o proporciona.
- **Autentica√ß√µes**: Neste exemplo apenas por api key e basic, embora n√£o sejam seguras, s√£o bons exemplos de como aplicar a autentica√ß√£o, no cen√°rio real o m√≠nimo deveria ser por JWT, OAuth ou outros.
- **Documenta√ß√£o automatica**: A rota autenticada com basic /docs cria uma documenta√ß√£o swagger automatica, tem como associar os modelos de respostas em formatos espec√≠ficos para melhorar mais os retornos esperados em termos de modelo de dados e status.

## üí° Cen√°rio real

O que eu iria propor em um cen√°rio real de produ√ß√£o?

Este cen√°rio de emiss√£o de boletos n√£o deve ser feito em uma API, o cen√°rio ideal envolveria uma arquitetura de recursos Cloud (Ex: Serverless com API Gateway, SQS, Lambdas e SES na AWS, Terraform, Pub Sub, Cloud functions e SendGrid na GCP). 

SQS e Pub Sub podem ser utilzados para fazer repeti√ß√µes em caso de falhas, e em cen√°rios de automa√ß√£o de dados j√° populados em uma base, o ideal era o uso de eventos do AWS CloudWatch ou GCP Cloud Scheduler para a execu√ß√£o dessas etapas de forma autom√°tica e peri√≥dica.

Contudo com essa complexidade, seria interessante um framework de IaC para integrar nos pipelines CI CD para deploys automaticos da infraestrutura, por isso coloquei tamb√©m Serverless e Terraform como recursos principais dos quais tenho esperi√™ncia e gosto de trabalhar.

## üìú Build na Cloud para DEV e PROD

Esta solu√ß√£o usa de CI CD para subir esta aplica√ß√£o para um Cloud Run da GCP atrav√©s de commits para a master ou development (Atualmente criei apenas a branch master). Pontos de melhoria:
- Aplicar linting
- Aplicar testes
- Aplicar commits semanticos
- Se a infraestrutura for complexa, usar IaC com Terraform, Serverless ou outros

## üíª Execu√ß√£o local

Para executar localmente:
- Verifique se o docker e docker-compose estao funcionais na sua maquina
- Crie um .env com base no .env.example (Para agilidade apenas copie o arquivo e renomeie)
- Execute `docker-compose up` (A base de dados ser√° criada com os modelos ORMs no caso do Sqlite)

## ü§î Como contribuir

Para contribuir:
- Fa√ßa uma branch a partir da development com o nome adequada √† atividade:
  - ```feature/add-endpoint```
- Fa√ßa os commits/push para a branch.
- Fa√ßa um PR (Pull Request) para a branch development/master.
- Ap√≥s seu PR ser aprovado, fa√ßa o merge e verifique se o deploy do GitHub Actions/CloudBuild n√£o apresenta erros.